
current GPU: NVIDIA A40
0it [00:00, ?it/s]
torch.Size([222623, 128])
torch.Size([222623, 256])
torch.Size([222623, 512])
torch.Size([223302, 128])
torch.Size([223302, 256])

1it [00:06,  6.07s/it]
Traceback (most recent call last):
  File "training.py", line 189, in <module>
    main()
  File "training.py", line 184, in main
    train(model, train_loader, val_loader, device, config)
  File "training.py", line 49, in train
    loss.backward()
  File "/u/home/zhousiy/.conda/envs/BodyMeshGNN/lib/python3.8/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/u/home/zhousiy/.conda/envs/BodyMeshGNN/lib/python3.8/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.48 GiB (GPU 1; 44.37 GiB total capacity; 20.77 GiB already allocated; 4.28 GiB free; 23.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF