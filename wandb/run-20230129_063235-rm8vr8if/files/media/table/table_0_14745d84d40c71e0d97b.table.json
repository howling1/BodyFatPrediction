{"columns": ["params"], "data": [["{'experiment_name': 'age_prediction_5k', 'batch_size': 32, 'epochs': 2000, 'learning_rate': 0.001, 'weight_decay': 0.1, 'task': 'regression', 'print_every_n': 200, 'validate_every_n': 200}"], ["{'gnn_conv': <class 'torch_geometric.nn.conv.sage_conv.SAGEConv'>, 'in_features': 3, 'encoder_channels': [16], 'inout_conv_channel': 64, 'num_layers': 4, 'decoder_channels': [32], 'num_classes': 1, 'apply_dropedge': True, 'apply_bn': True}"], ["DenseGNN(\n  (input_encoder): Sequential(\n    (0): Linear(in_features=3, out_features=16, bias=True)\n    (1): Identity()\n  )\n  (conv_layers): ModuleList(\n    (0): SAGEConv(16, 64, aggr=mean)\n    (1): SAGEConv(64, 64, aggr=mean)\n    (2): SAGEConv(64, 64, aggr=mean)\n    (3): SAGEConv(64, 64, aggr=mean)\n  )\n  (bn_layers): ModuleList(\n    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (final_projection): Sequential(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=1, bias=True)\n    (3): Identity()\n  )\n)"]]}