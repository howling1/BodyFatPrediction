{"columns": ["params"], "data": [["{'experiment_name': 'age_prediction_5k', 'batch_size': 32, 'epochs': 2000, 'learning_rate': 0.003, 'weight_decay': 0.01, 'task': 'regression', 'print_every_n': 200, 'validate_every_n': 200}"], ["{'gnn_conv': <class 'torch_geometric.nn.conv.sage_conv.SAGEConv'>, 'in_features': 3, 'inout_conv_channel': 64, 'num_layers': 5, 'num_skip_layers': 1, 'encoder_channels': [1024], 'decoder_channels': [256, 64], 'num_classes': 1, 'aggregation': 'max', 'apply_dropedge': True, 'apply_bn': True, 'apply_dropout': True}"], ["ResGNN(\n  (conv_layers): ModuleList(\n    (0): SAGEConv(3, 64, aggr=mean)\n    (1): SAGEConv(64, 64, aggr=mean)\n    (2): SAGEConv(64, 64, aggr=mean)\n    (3): SAGEConv(64, 64, aggr=mean)\n    (4): SAGEConv(64, 64, aggr=mean)\n  )\n  (bn_layers): ModuleList(\n    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (linear_encoder): Sequential(\n    (0): Linear(in_features=320, out_features=1024, bias=True)\n    (1): ReLU()\n  )\n  (final_projection): Sequential(\n    (0): Linear(in_features=1024, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=256, out_features=64, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=64, out_features=1, bias=True)\n    (7): Identity()\n  )\n)"]]}