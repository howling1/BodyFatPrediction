{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDataset(InMemoryDataset):\n",
    "    def __init__(self, raw_data_root, dataset_root, basic_features_path, ids_root, target_name, gender, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Creates the InMemoryDataset object, convenient structure for graph training.\n",
    "        :param raw_data_root: path for the input mesh data \n",
    "        :param dataset_root: path where the in memory dataset will be written\n",
    "        :param basic_features_path: path of the \"basic_features.csv\"\n",
    "        :param ids_root: path of the file saving the ids of selected samples\n",
    "        :param target_name: name of the feature to be predicted\n",
    "            [\"sex\",\"bmi\",\"age\",\"weight\",\"height\"]\n",
    "        :param gender: 0 for female, 1 for male\n",
    "        \"\"\"\n",
    "        self.ids = np.load(ids_root)\n",
    "        self.raw_data_root = raw_data_root\n",
    "        self.basic_features_path = basic_features_path\n",
    "        self.target_name = target_name\n",
    "\n",
    "        if not os.path.exists(dataset_root):\n",
    "            os.makedirs(dataset_root)\n",
    "        super(IMDataset, self).__init__(root = dataset_root, transform = transform, pre_transform = pre_transform)\n",
    "        if gender == 0: #female\n",
    "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        elif gender == 1: #male\n",
    "            self.data, self.slices = torch.load(self.processed_paths[1])\n",
    " \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        file_names = (pd.Series(self.ids).astype(str) + \".ply\").values.tolist()\n",
    "        return [os.path.join(str(Path(self.raw_data_root)), file_name) for file_name in file_names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        processed_root = self.root + \"/\" + self.target_name\n",
    "\n",
    "        if not os.path.exists(processed_root):\n",
    "            os.makedirs(processed_root)\n",
    "\n",
    "        return [processed_root + \"/female_dataset.pt\", processed_root + \"/male_dataset.pt\"]\n",
    " \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Combines the vertex coordinates, edge connectivity indexes and chosen target feature.\n",
    "        \"\"\"\n",
    "        male_data_list = []\n",
    "        female_data_list = []\n",
    "\n",
    "        if self.target_name == \"vat\":\n",
    "            cols = [\"22407-2.0\"]\n",
    "        elif self.target_name == \"asat\":\n",
    "            cols = [\"22408-2.0\"]\n",
    "        elif self.target_name == \"all\":\n",
    "            cols = [\"22407-2.0\", \"22408-2.0\"]\n",
    "\n",
    "        features = pd.read_csv(self.basic_features_path, usecols =[\"eid\", \"31-0.0\"] + cols)\n",
    "\n",
    "        for file_path in self.raw_file_names:\n",
    "            _id = int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "            _sex = int(features[features['eid']==_id][\"31-0.0\"].values[0]) #female: 0, male: 1\n",
    "            _y = torch.tensor(features[features['eid']==_id][cols].values[0]).double()\n",
    "            if torch.isnan(_y).any().item():\n",
    "                continue\n",
    "            \n",
    "            _mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "            _vertices = torch.from_numpy(np.asarray(_mesh.vertices)).double()\n",
    "            _triangles = _mesh.triangles\n",
    "\n",
    "            \"\"\"\n",
    "            necessary to get the edge connectivity since the original data has only face connectivity\n",
    "            we need [0,1],[1,2],[0,2],[1,0],[2,1],[2,0] instead of [0,1,2]\n",
    "            including reverse as well to make the graph bi-directional\n",
    "            \"\"\"\n",
    "            edge_list = []\n",
    "            for t in _triangles:\n",
    "                edge_list = edge_list + [[t[0], t[1]], [t[1], t[0]], [t[0], t[2]], [t[2], t[0]], [t[1], t[2]], [t[2], t[1]]]\n",
    "\n",
    "            _edges = torch.from_numpy(np.unique(np.array(edge_list), axis=0)).long().permute(1, 0)\n",
    "\n",
    "            if _sex == 0:\n",
    "                female_data_list.append(Data(x=_vertices, edge_index=_edges, y=_y))\n",
    "            else:\n",
    "                male_data_list.append(Data(x=_vertices, edge_index=_edges, y=_y))\n",
    "        \n",
    "        data_female, slices_female = self.collate(female_data_list)\n",
    "        data_male, slices_male = self.collate(male_data_list)\n",
    "        #saves sex based datasets\n",
    "        torch.save((data_female, slices_female), self.processed_paths[0])\n",
    "        torch.save((data_male, slices_male), self.processed_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTERED_ROOT = \"/vol/space/projects/ukbb/projects/silhouette/registered_25\" # the path of the dir saving the .ply registered data\n",
    "INMEMORY_ROOT = '/vol/space/projects/ukbb/projects/silhouette/imdataset/registered25_imdataset' # the root dir path to save all the artifacts ralated of the InMemoryDataset\n",
    "FEATURES_PATH = \"/vol/space/projects/ukbb/projects/silhouette/ukb668815_imaging.csv\"   \n",
    "IDS_PATH = \"/vol/space/projects/ukbb/projects/silhouette/eids_filtered.npy\"\n",
    "TARGET = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_female \u001b[39m=\u001b[39m IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m dataset_male \u001b[39m=\u001b[39m IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, \u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m, in \u001b[0;36mIMDataset.__init__\u001b[0;34m(self, raw_data_root, dataset_root, basic_features_path, ids_root, target_name, gender, transform, pre_transform)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(dataset_root):\n\u001b[1;32m     19\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(dataset_root)\n\u001b[0;32m---> 20\u001b[0m \u001b[39msuper\u001b[39;49m(IMDataset, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root \u001b[39m=\u001b[39;49m dataset_root, transform \u001b[39m=\u001b[39;49m transform, pre_transform \u001b[39m=\u001b[39;49m pre_transform)\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m gender \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m#female\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/gr_siyu/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:55\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     49\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m ):\n\u001b[0;32m---> 55\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/gr_siyu/lib/python3.8/site-packages/torch_geometric/data/dataset.py:94\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[0;32m~/.conda/envs/gr_siyu/lib/python3.8/site-packages/torch_geometric/data/dataset.py:211\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m    210\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    213\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    214\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[0;32mIn[32], line 77\u001b[0m, in \u001b[0;36mIMDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m edge_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m _triangles:\n\u001b[0;32m---> 77\u001b[0m     edge_list \u001b[39m=\u001b[39m edge_list \u001b[39m+\u001b[39m [[t[\u001b[39m0\u001b[39m], t[\u001b[39m1\u001b[39m]], [t[\u001b[39m1\u001b[39m], t[\u001b[39m0\u001b[39m]], [t[\u001b[39m0\u001b[39m], t[\u001b[39m2\u001b[39m]], [t[\u001b[39m2\u001b[39m], t[\u001b[39m0\u001b[39m]], [t[\u001b[39m1\u001b[39m], t[\u001b[39m2\u001b[39m]], [t[\u001b[39m2\u001b[39m], t[\u001b[39m1\u001b[39m]]]\n\u001b[1;32m     79\u001b[0m _edges \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39marray(edge_list), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m _sex \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_female = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 0)\n",
    "dataset_male = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9143, 8.2004], dtype=torch.float64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_female)[6].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9346, 9.4861], dtype=torch.float64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_female)[2].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 7])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(range(20))\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=False)\n",
    "\n",
    "for (train_index_female, val_index_female), (train_index_male, val_index_male) in kf.split(dev_female_x):\n",
    "    train_female = [dev_female_x[i], dev_female_y[i] for i in train_index_female]\n",
    "    val_female = [dev_female_x[i], dev_female_y[i] for i in val_index_female]\n",
    "    train_male = [dev_male_x[i], dev_male_y[i] for i in train_index_male]\n",
    "    val_male = [dev_male_x[i], dev_male_y[i] for i in val_index_male]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr_siyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
