{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDataset(InMemoryDataset):\n",
    "    def __init__(self, raw_data_root, dataset_root, basic_features_path, ids_root, target_name, gender, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Creates the InMemoryDataset object, convenient structure for graph training.\n",
    "        :param raw_data_root: path for the input mesh data \n",
    "        :param dataset_root: path where the in memory dataset will be written\n",
    "        :param basic_features_path: path of the \"basic_features.csv\"\n",
    "        :param ids_root: path of the file saving the ids of selected samples\n",
    "        :param target_name: name of the feature to be predicted\n",
    "            [\"sex\",\"bmi\",\"age\",\"weight\",\"height\"]\n",
    "        :param gender: 0 for female, 1 for male\n",
    "        \"\"\"\n",
    "        self.ids = np.load(ids_root)\n",
    "        self.raw_data_root = raw_data_root\n",
    "        self.basic_features_path = basic_features_path\n",
    "        self.target_name = target_name\n",
    "\n",
    "        if not os.path.exists(dataset_root):\n",
    "            os.makedirs(dataset_root)\n",
    "        super(IMDataset, self).__init__(root = dataset_root, transform = transform, pre_transform = pre_transform)\n",
    "        if gender == 0: #female\n",
    "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        elif gender == 1: #male\n",
    "            self.data, self.slices = torch.load(self.processed_paths[1])\n",
    " \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        file_names = (pd.Series(self.ids).astype(str) + \".ply\").values.tolist()\n",
    "        return [os.path.join(str(Path(self.raw_data_root)), file_name) for file_name in file_names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        processed_root = self.root + \"/\" + self.target_name\n",
    "\n",
    "        if not os.path.exists(processed_root):\n",
    "            os.makedirs(processed_root)\n",
    "\n",
    "        return [processed_root + \"/female_dataset.pt\", processed_root + \"/male_dataset.pt\"]\n",
    " \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Combines the vertex coordinates, edge connectivity indexes and chosen target feature.\n",
    "        \"\"\"\n",
    "        male_data_list = []\n",
    "        female_data_list = []\n",
    "\n",
    "        if self.target_name == \"vat\":\n",
    "            col = \"22407-2.0\"\n",
    "        elif self.target_name == \"asat\":\n",
    "            col = \"22408-2.0\"\n",
    "\n",
    "        features = pd.read_csv(self.basic_features_path, usecols =[\"eid\", \"31-0.0\", col])\n",
    "\n",
    "        for file_path in self.raw_file_names:\n",
    "            _id = int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "            _sex = int(features[features['eid']==_id][\"31-0.0\"].values[0]) #female: 0, male: 1\n",
    "            _y = torch.tensor(features[features['eid']==_id][col].values).double()\n",
    "            if torch.isnan(_y[0]):\n",
    "                continue\n",
    "            \n",
    "            _mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "            _vertices = torch.from_numpy(np.asarray(_mesh.vertices)).double()\n",
    "            _triangles = _mesh.triangles \n",
    "\n",
    "            \"\"\"\n",
    "            necessary to get the edge connectivity since the original data has only face connectivity\n",
    "            we need [0,1],[1,2],[0,2],[1,0],[2,1],[2,0] instead of [0,1,2]\n",
    "            including reverse as well to make the graph bi-directional\n",
    "            \"\"\"\n",
    "            edge_list = []\n",
    "            for t in _triangles:\n",
    "                edge_list = edge_list + [[t[0], t[1]], [t[1], t[0]], [t[0], t[2]], [t[2], t[0]], [t[1], t[2]], [t[2], t[1]]]\n",
    "\n",
    "            _edges = torch.from_numpy(np.unique(np.array(edge_list), axis=0)).long().permute(1, 0)\n",
    "\n",
    "            if _sex == 0:\n",
    "                female_data_list.append(Data(x=_vertices, edge_index=_edges, y=_y))\n",
    "            else:\n",
    "                male_data_list.append(Data(x=_vertices, edge_index=_edges, y=_y))\n",
    "        \n",
    "        data_female, slices_female = self.collate(female_data_list)\n",
    "        data_male, slices_male = self.collate(male_data_list)\n",
    "        #saves sex based datasets\n",
    "        torch.save((data_female, slices_female), self.processed_paths[0])\n",
    "        torch.save((data_male, slices_male), self.processed_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTERED_ROOT = \"/vol/space/projects/ukbb/projects/silhouette/registered_1\" # the path of the dir saving the .ply registered data\n",
    "INMEMORY_ROOT = '/vol/space/projects/ukbb/projects/silhouette/imdataset/registered1_asat' # the root dir path to save all the artifacts ralated of the InMemoryDataset\n",
    "FEATURES_PATH = \"/vol/space/projects/ukbb/projects/silhouette/ukb668815_imaging.csv\"   \n",
    "IDS_PATH = \"/vol/space/projects/ukbb/projects/silhouette/eids_filtered.npy\"\n",
    "TARGET = \"asat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_female = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 0)\n",
    "dataset_male = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_female1k = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 0)\n",
    "dataset_male1k = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---fold----\n",
      "train: [2 3 4 5]\n",
      "test: [0 1]\n",
      "---fold----\n",
      "train: [0 1 4 5]\n",
      "test: [2 3]\n",
      "---fold----\n",
      "train: [0 1 2 3]\n",
      "test: [4 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "kf = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "for train_index, test_index in kf.split(a):\n",
    "    print(\"---fold----\")\n",
    "\n",
    "    print(\"train:\", train_index)\n",
    "    print(\"test:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr_siyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
