{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDataset(InMemoryDataset):\n",
    "    def __init__(self, raw_data_root, dataset_root, basic_features_path, ids_root, target_name, gender, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Creates the InMemoryDataset object, convenient structure for graph training.\n",
    "        :param raw_data_root: path for the input mesh data \n",
    "        :param dataset_root: path where the in memory dataset will be written\n",
    "        :param basic_features_path: path of the \"basic_features.csv\"\n",
    "        :param ids_root: path of the file saving the ids of selected samples\n",
    "        :param target_name: name of the feature to be predicted\n",
    "            [\"sex\",\"bmi\",\"age\",\"weight\",\"height\"]\n",
    "        :param gender: 0 for female, 1 for male\n",
    "        \"\"\"\n",
    "        self.ids = np.load(ids_root)\n",
    "        self.raw_data_root = raw_data_root\n",
    "        self.basic_features_path = basic_features_path\n",
    "        self.target_name = target_name\n",
    "\n",
    "        if not os.path.exists(dataset_root):\n",
    "            os.makedirs(dataset_root)\n",
    "        super(IMDataset, self).__init__(root = dataset_root, transform = transform, pre_transform = pre_transform)\n",
    "        if gender == 0: #female\n",
    "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        elif gender == 1: #male\n",
    "            self.data, self.slices = torch.load(self.processed_paths[1])\n",
    " \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        file_names = (pd.Series(self.ids).astype(str) + \".ply\").values.tolist()\n",
    "        return [os.path.join(str(Path(self.raw_data_root)), file_name) for file_name in file_names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        processed_root = self.root + \"/\" + self.target_name\n",
    "\n",
    "        if not os.path.exists(processed_root):\n",
    "            os.makedirs(processed_root)\n",
    "\n",
    "        return [processed_root + \"/female_dataset.pt\", processed_root + \"/male_dataset.pt\"]\n",
    " \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Combines the vertex coordinates, edge connectivity indexes and chosen target feature.\n",
    "        \"\"\"\n",
    "        male_data_list = []\n",
    "        female_data_list = []\n",
    "\n",
    "        if self.target_name == \"vat\":\n",
    "            col = \"22407-2.0\"\n",
    "        elif self.target_name == \"asat\":\n",
    "            col = \"22408-2.0\"\n",
    "\n",
    "        features = pd.read_csv(self.basic_features_path, usecols =[\"eid\", \"31-0.0\", col])\n",
    "\n",
    "        for file_path in self.raw_file_names:\n",
    "            _id = int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "            _sex = int(features[features['eid']==_id][\"31-0.0\"].values[0]) #female: 0, male: 1\n",
    "            _y = torch.tensor(features[features['eid']==_id][col].values).double()\n",
    "            if torch.isnan(_y[0]):\n",
    "                continue\n",
    "            \n",
    "            _mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "            _vertices = torch.from_numpy(np.asarray(_mesh.vertices)).double()\n",
    "            _triangles = _mesh.triangles \n",
    "\n",
    "            \"\"\"\n",
    "            necessary to get the edge connectivity since the original data has only face connectivity\n",
    "            we need [0,1],[1,2],[0,2],[1,0],[2,1],[2,0] instead of [0,1,2]\n",
    "            including reverse as well to make the graph bi-directional\n",
    "            \"\"\"\n",
    "            edge_list = []\n",
    "            for t in _triangles:\n",
    "                edge_list = edge_list + [[t[0], t[1]], [t[1], t[0]], [t[0], t[2]], [t[2], t[0]], [t[1], t[2]], [t[2], t[1]]]\n",
    "\n",
    "            _edges = torch.from_numpy(np.unique(np.array(edge_list), axis=0)).long().permute(1, 0)\n",
    "\n",
    "            if _sex == 0:\n",
    "                female_data_list.append(Data(x=_vertices, edge_index=_edges, y=_y))\n",
    "            else:\n",
    "                male_data_list.append(Data(x=_vertices, edge_index=_edges, y=_y))\n",
    "        \n",
    "        data_female, slices_female = self.collate(female_data_list)\n",
    "        data_male, slices_male = self.collate(male_data_list)\n",
    "        #saves sex based datasets\n",
    "        torch.save((data_female, slices_female), self.processed_paths[0])\n",
    "        torch.save((data_male, slices_male), self.processed_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTERED_ROOT = \"/vol/space/projects/ukbb/projects/silhouette/registered_5\" # the path of the dir saving the .ply registered data\n",
    "INMEMORY_ROOT = '/vol/space/projects/ukbb/projects/silhouette/imdataset/registered5_imdataset' # the root dir path to save all the artifacts ralated of the InMemoryDataset\n",
    "FEATURES_PATH = \"/vol/space/projects/ukbb/projects/silhouette/ukb668815_imaging.csv\"   \n",
    "IDS_PATH = \"/vol/space/projects/ukbb/projects/silhouette/eids_filtered.npy\"\n",
    "TARGET = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_female = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 0)\n",
    "dataset_male = IMDataset(REGISTERED_ROOT, INMEMORY_ROOT, FEATURES_PATH, IDS_PATH, TARGET, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_list = list(dataset_female)\n",
    "male_list = list(dataset_male)\n",
    "\n",
    "dev_female, test_female = train_test_split(female_list, test_size=1/6, random_state=42)\n",
    "dev_male, test_male = train_test_split(male_list, test_size=1/6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10175"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10906\n",
      "10175\n",
      "10906\n",
      "10175\n",
      "10906\n",
      "10175\n",
      "10906\n",
      "10175\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "for (train_index_female, val_index_female), (train_index_male, val_index_male) in zip(kf.split(dev_female), kf.split(dev_male)):\n",
    "    print(len(train_index_female) + len(val_index_female))\n",
    "    print(len(train_index_male) + len(val_index_male))\n",
    "\n",
    "\n",
    "    # 划分数据集\n",
    "    # train_female = [dev_female[i] for i in train_index_female]\n",
    "    # val_female = [dev_female[i] for i in val_index_female]\n",
    "    # train_male = [dev_male[i] for i in train_index_male]\n",
    "    # val_male = [dev_male[i] for i in val_index_male]\n",
    "\n",
    "    # print(len(train_female))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,1,2,3]\n",
    "a[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:58:48] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:58:48] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:58:48] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 21:58:48] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:58:48] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 21:58:49] CPU Model on constant consumption mode: AMD Ryzen Threadripper 3960X 24-Core Processor\n",
      "[codecarbon INFO @ 21:58:49] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:58:49]   Platform system: Linux-5.4.0-148-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 21:58:49]   Python version: 3.8.15\n",
      "[codecarbon INFO @ 21:58:49]   CodeCarbon version: 2.2.2\n",
      "[codecarbon INFO @ 21:58:49]   Available RAM : 251.625 GB\n",
      "[codecarbon INFO @ 21:58:49]   CPU count: 48\n",
      "[codecarbon INFO @ 21:58:49]   CPU model: AMD Ryzen Threadripper 3960X 24-Core Processor\n",
      "[codecarbon INFO @ 21:58:49]   GPU count: 1\n",
      "[codecarbon INFO @ 21:58:49]   GPU model: 1 x Quadro RTX 8000\n",
      "[codecarbon WARNING @ 21:58:51] Unable to access geographical location. Using 'Canada' as the default value - Exception : Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "tracker = EmissionsTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Emissions.get_country_emissions of <codecarbon.core.emissions.Emissions object at 0x7f3b88e8eeb0>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr_siyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
